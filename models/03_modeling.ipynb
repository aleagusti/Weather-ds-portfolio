{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00323481",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Select an Interpreter to start Jupyter\n",
      "\u001b[1;31mInstall 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "03 - Modeling (Regression) with Feature Ablation\n",
    "\n",
    "Goal\n",
    "----\n",
    "Predict daily precipitation (precipitation_sum) for Miami using Open-Meteo daily data.\n",
    "Run feature ablation experiments to quantify the signal contribution of:\n",
    "A) Base physical variables\n",
    "B) Seasonality (cyclical day-of-year)\n",
    "C) Memory (lags/rolling of precipitation)\n",
    "\n",
    "Notes\n",
    "-----\n",
    "- Code and comments are in English.\n",
    "- Plot titles/labels include Spanish + English.\n",
    "- We enforce temporal splits (no shuffling) to avoid leakage.\n",
    "\n",
    "Expected input\n",
    "--------------\n",
    "data/raw/open_meteo_miami_daily.csv\n",
    "\n",
    "Outputs\n",
    "-------\n",
    "- data/processed/ablation_results.csv\n",
    "- data/processed/predictions_best_experiment.csv\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Imports\n",
    "# =========================\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from __future__ import annotations\n",
    "\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Local feature engineering\n",
    "from src.features import (\n",
    "    build_base_features,\n",
    "    build_seasonal_features,\n",
    "    build_memory_features,\n",
    "    ensure_sorted_by_date,\n",
    ")\n",
    "\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "EXP_VERSION = \"v001\"\n",
    "PROJECT_ROOT = Path.cwd().parents[0]   # notebooks/ -> project root\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "RAW_PATH = PROJECT_ROOT / \"data\" / \"raw\" / \"open_meteo_miami_daily.csv\"\n",
    "OUT_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TARGET = \"precipitation_sum\"\n",
    "DATE_COL = \"date\"\n",
    "\n",
    "# Temporal split (no shuffle): last 20% as test\n",
    "TEST_FRACTION = 0.20\n",
    "\n",
    "# If True, model log(1 + precip) to reduce skew; metrics reported on original scale.\n",
    "USE_LOG_TARGET = False\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Load data\n",
    "# =========================\n",
    "\n",
    "if not RAW_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Raw dataset not found at: {RAW_PATH}. \"\n",
    "        \"Run the Open-Meteo ingestion script first.\"\n",
    "    )\n",
    "\n",
    "raw = pd.read_csv(RAW_PATH)\n",
    "\n",
    "# Enforce date parsing\n",
    "raw[DATE_COL] = pd.to_datetime(raw[DATE_COL])\n",
    "raw = ensure_sorted_by_date(raw, date_col=DATE_COL)\n",
    "\n",
    "# Basic sanity checks\n",
    "required_cols = {\n",
    "    DATE_COL,\n",
    "    TARGET,\n",
    "    \"temperature_2m_max\",\n",
    "    \"temperature_2m_min\",\n",
    "    \"temperature_2m_mean\",\n",
    "    \"relative_humidity_2m_mean\",\n",
    "    \"surface_pressure_mean\",\n",
    "    \"wind_speed_10m_mean\",\n",
    "    \"cloud_cover_mean\",\n",
    "}\n",
    "missing = sorted(list(required_cols - set(raw.columns)))\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Missing required columns in raw dataset: {missing}\")\n",
    "\n",
    "raw.head()\n",
    "\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Quick target diagnostics\n",
    "# =========================\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(raw[TARGET].values, bins=60)\n",
    "plt.title(\"Distribución de precipitación diaria / Daily precipitation distribution\")\n",
    "plt.xlabel(\"Precipitación (mm) / Precipitation (mm)\")\n",
    "plt.ylabel(\"Frecuencia / Frequency\")\n",
    "plt.show()\n",
    "\n",
    "zero_rate = (raw[TARGET] == 0).mean()\n",
    "print(f\"Share of zero-precip days / Proporción de días con 0 mm: {zero_rate:.3f}\")\n",
    "\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Feature groups (definitions)\n",
    "# =========================\n",
    "\n",
    "# Base physical variables (A)\n",
    "BASE_FEATURES = [\n",
    "    \"temperature_2m_mean\",\n",
    "    \"relative_humidity_2m_mean\",\n",
    "    \"cloud_cover_mean\",\n",
    "    \"surface_pressure_mean\",\n",
    "    \"wind_speed_10m_mean\",\n",
    "    \"temp_range\",  # engineered but still physical: max - min\n",
    "]\n",
    "\n",
    "# Seasonality (B)\n",
    "SEASONAL_FEATURES = [\n",
    "    \"doy_sin\",\n",
    "    \"doy_cos\",\n",
    "]\n",
    "\n",
    "# Memory (C)\n",
    "MEMORY_FEATURES = [\n",
    "    \"precip_lag_1\",\n",
    "    \"precip_lag_3\",\n",
    "    \"precip_lag_7\",\n",
    "    \"precip_roll_3\",\n",
    "    \"precip_roll_7\",\n",
    "]\n",
    "\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Build feature-enriched master table\n",
    "# =========================\n",
    "\n",
    "# 1) Add base physical engineered features\n",
    "feat = build_base_features(raw)\n",
    "\n",
    "# 2) Add seasonal cyclical encoding\n",
    "feat = build_seasonal_features(feat)\n",
    "\n",
    "# 3) Add precipitation memory features (lags + rolling)\n",
    "feat = build_memory_features(feat)\n",
    "\n",
    "# Keep only numeric features + date + target for modeling convenience\n",
    "feat = ensure_sorted_by_date(feat, date_col=DATE_COL)\n",
    "feat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb5f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =========================\n",
    "# Train/test split (temporal)\n",
    "# =========================\n",
    "\n",
    "n = len(feat)\n",
    "split_idx = int(np.floor((1.0 - TEST_FRACTION) * n))\n",
    "\n",
    "train_df = feat.iloc[:split_idx].copy()\n",
    "test_df = feat.iloc[split_idx:].copy()\n",
    "\n",
    "print(\n",
    "    \"Train period / Período train:\",\n",
    "    train_df[DATE_COL].min().date(),\n",
    "    \"→\",\n",
    "    train_df[DATE_COL].max().date(),\n",
    ")\n",
    "print(\n",
    "    \"Test period / Período test:\",\n",
    "    test_df[DATE_COL].min().date(),\n",
    "    \"→\",\n",
    "    test_df[DATE_COL].max().date(),\n",
    ")\n",
    "\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Experiment definitions (feature ablation)\n",
    "# =========================\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Experiment:\n",
    "    name: str\n",
    "    feature_list: List[str]\n",
    "    notes: str\n",
    "\n",
    "\n",
    "def make_experiments() -> List[Experiment]:\n",
    "    \"\"\"Create the ablation experiment list.\"\"\"\n",
    "\n",
    "    # A) Base only\n",
    "    exp1 = Experiment(\n",
    "        name=\"EXP1_base\",\n",
    "        feature_list=BASE_FEATURES,\n",
    "        notes=\"Only physical state variables / Solo variables físicas\",\n",
    "    )\n",
    "\n",
    "    # A + B\n",
    "    exp2 = Experiment(\n",
    "        name=\"EXP2_base_season\",\n",
    "        feature_list=BASE_FEATURES + SEASONAL_FEATURES,\n",
    "        notes=\"Physical + annual cycle / Física + estacionalidad\",\n",
    "    )\n",
    "\n",
    "    # C only\n",
    "    exp3 = Experiment(\n",
    "        name=\"EXP3_memory\",\n",
    "        feature_list=MEMORY_FEATURES,\n",
    "        notes=\"Only precipitation persistence / Solo persistencia\",\n",
    "    )\n",
    "\n",
    "    # B + C\n",
    "    exp4 = Experiment(\n",
    "        name=\"EXP4_season_memory\",\n",
    "        feature_list=SEASONAL_FEATURES + MEMORY_FEATURES,\n",
    "        notes=\"Annual cycle + persistence / Estacionalidad + persistencia\",\n",
    "    )\n",
    "\n",
    "    # A + C\n",
    "    exp5 = Experiment(\n",
    "        name=\"EXP5_base_memory\",\n",
    "        feature_list=BASE_FEATURES + MEMORY_FEATURES,\n",
    "        notes=\"Physical + persistence / Física + persistencia\",\n",
    "    )\n",
    "\n",
    "    # A + B + C (full)\n",
    "    exp6 = Experiment(\n",
    "        name=\"EXP6_full\",\n",
    "        feature_list=BASE_FEATURES + SEASONAL_FEATURES + MEMORY_FEATURES,\n",
    "        notes=\"Full model / Modelo completo\",\n",
    "    )\n",
    "\n",
    "    # Internal ablation: lags-only vs roll-only (with A+B)\n",
    "    exp7 = Experiment(\n",
    "        name=\"EXP7_full_lags_only\",\n",
    "        feature_list=BASE_FEATURES + SEASONAL_FEATURES + [\n",
    "            \"precip_lag_1\",\n",
    "            \"precip_lag_7\",\n",
    "        ],\n",
    "        notes=\"A+B + lags only / A+B + solo lags\",\n",
    "    )\n",
    "\n",
    "    exp8 = Experiment(\n",
    "        name=\"EXP8_full_roll_only\",\n",
    "        feature_list=BASE_FEATURES + SEASONAL_FEATURES + [\n",
    "            \"precip_roll_7\",\n",
    "        ],\n",
    "        notes=\"A+B + roll only / A+B + solo rolling\",\n",
    "    )\n",
    "\n",
    "    return [exp1, exp2, exp3, exp4, exp5, exp6, exp7, exp8]\n",
    "\n",
    "\n",
    "EXPERIMENTS = make_experiments()\n",
    "len(EXPERIMENTS), [e.name for e in EXPERIMENTS]\n",
    "\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Models\n",
    "# =========================\n",
    "\n",
    "MODELS: Dict[str, object] = {\n",
    "    \"Linear\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0, random_state=RANDOM_STATE),\n",
    "    \"Lasso\": Lasso(alpha=0.001, random_state=RANDOM_STATE, max_iter=50_000),\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "        n_estimators=400,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Helpers: dataset build, training, evaluation\n",
    "# =========================\n",
    "\n",
    "\n",
    "def prepare_xy(\n",
    "    train: pd.DataFrame,\n",
    "    test: pd.DataFrame,\n",
    "    features: List[str],\n",
    "    target: str,\n",
    "    use_log_target: bool,\n",
    ") -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:\n",
    "    \"\"\"Prepare X/y for train/test with dropna applied consistently.\"\"\"\n",
    "\n",
    "    needed = [DATE_COL] + features + [target]\n",
    "\n",
    "    train_sub = train[needed].dropna().copy()\n",
    "    test_sub = test[needed].dropna().copy()\n",
    "\n",
    "    X_train = train_sub[features]\n",
    "    y_train = train_sub[target]\n",
    "    X_test = test_sub[features]\n",
    "    y_test = test_sub[target]\n",
    "\n",
    "    if use_log_target:\n",
    "        y_train = np.log1p(y_train)\n",
    "        y_test = np.log1p(y_test)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "def inverse_target(y: np.ndarray | pd.Series, use_log_target: bool) -> np.ndarray:\n",
    "    \"\"\"Invert log1p transform back to mm scale.\"\"\"\n",
    "\n",
    "    y_arr = np.asarray(y)\n",
    "    if use_log_target:\n",
    "        return np.expm1(y_arr)\n",
    "    return y_arr\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_regression(y_true_mm: np.ndarray, y_pred_mm: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"Compute MAE, RMSE, R2 on original precipitation scale (mm).\"\"\"\n",
    "\n",
    "    mae = mean_absolute_error(y_true_mm, y_pred_mm)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_mm, y_pred_mm))\n",
    "    r2 = r2_score(y_true_mm, y_pred_mm)\n",
    "\n",
    "    return {\"MAE\": float(mae), \"RMSE\": float(rmse), \"R2\": float(r2)}\n",
    "\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Run ablation grid\n",
    "# =========================\n",
    "\n",
    "results_rows: List[Dict[str, object]] = []\n",
    "predictions_store: Dict[Tuple[str, str], pd.DataFrame] = {}\n",
    "\n",
    "for exp in EXPERIMENTS:\n",
    "    for model_name, model in MODELS.items():\n",
    "\n",
    "        X_train, y_train, X_test, y_test = prepare_xy(\n",
    "            train_df,\n",
    "            test_df,\n",
    "            exp.feature_list,\n",
    "            TARGET,\n",
    "            USE_LOG_TARGET,\n",
    "        )\n",
    "\n",
    "        # Fit\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Bring to original mm scale\n",
    "        y_true_mm = inverse_target(y_test, USE_LOG_TARGET)\n",
    "        y_pred_mm = inverse_target(y_pred, USE_LOG_TARGET)\n",
    "\n",
    "        metrics = evaluate_regression(y_true_mm, y_pred_mm)\n",
    "\n",
    "        row = {\n",
    "            \"experiment\": exp.name,\n",
    "            \"model\": model_name,\n",
    "            \"n_train\": int(len(X_train)),\n",
    "            \"n_test\": int(len(X_test)),\n",
    "            \"features\": \",\".join(exp.feature_list),\n",
    "            \"notes\": exp.notes,\n",
    "            \"use_log_target\": USE_LOG_TARGET,\n",
    "            **metrics,\n",
    "        }\n",
    "        results_rows.append(row)\n",
    "\n",
    "        # Store predictions for later inspection\n",
    "        preds_df = test_df[[DATE_COL]].copy()\n",
    "        preds_df = preds_df.loc[test_df.index.isin(X_test.index)].copy()\n",
    "        preds_df[\"y_true_mm\"] = y_true_mm\n",
    "        preds_df[\"y_pred_mm\"] = y_pred_mm\n",
    "\n",
    "        predictions_store[(exp.name, model_name)] = preds_df\n",
    "\n",
    "results = pd.DataFrame(results_rows)\n",
    "results.sort_values([\"RMSE\", \"MAE\"]).head(10)\n",
    "\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Save results\n",
    "# =========================\n",
    "results_path = OUT_DIR / f\"ablation_results_{EXP_VERSION}.csv\"\n",
    "results.to_csv(results_path, index=False)\n",
    "print(f\"[SAVE] Ablation results -> {results_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77152cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =========================\n",
    "# Compare experiments visually (best per experiment)\n",
    "# =========================\n",
    "\n",
    "# Pick the best model per experiment by RMSE\n",
    "best_per_exp = (\n",
    "    results.sort_values([\"experiment\", \"RMSE\", \"MAE\"]).groupby(\"experiment\").head(1)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "best_per_exp\n",
    "\n",
    "\n",
    "# %%\n",
    "# Bar plot of RMSE per experiment (best model)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plt.bar(best_per_exp[\"experiment\"], best_per_exp[\"RMSE\"].values)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"RMSE por experimento (mejor modelo) / RMSE per experiment (best model)\")\n",
    "plt.ylabel(\"RMSE (mm)\")\n",
    "plt.xlabel(\"Experimento / Experiment\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =========================\n",
    "# Inspect the overall best run (by RMSE)\n",
    "# =========================\n",
    "\n",
    "best_row = results.sort_values([\"RMSE\", \"MAE\"]).iloc[0]\n",
    "best_exp = best_row[\"experiment\"]\n",
    "best_model = best_row[\"model\"]\n",
    "\n",
    "print(\"Best run / Mejor corrida:\")\n",
    "print(best_row[[\"experiment\", \"model\", \"MAE\", \"RMSE\", \"R2\"]])\n",
    "\n",
    "preds_best = predictions_store[(best_exp, best_model)].copy()\n",
    "\n",
    "# Save predictions\n",
    "pred_path = OUT_DIR / f\"predictions_best_{EXP_VERSION}.csv\"\n",
    "preds_best.to_csv(pred_path, index=False)\n",
    "print(f\"[SAVE] Best predictions -> {pred_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fa0600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Plot: true vs predicted (best)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plt.plot(preds_best[DATE_COL], preds_best[\"y_true_mm\"].values, label=\"Real / Actual\")\n",
    "plt.plot(preds_best[DATE_COL], preds_best[\"y_pred_mm\"].values, label=\"Predicho / Predicted\")\n",
    "plt.title(\n",
    "    f\"Precipitación real vs predicha / Actual vs predicted precipitation\\n{best_exp} | {best_model}\"\n",
    ")\n",
    "plt.xlabel(\"Fecha / Date\")\n",
    "plt.ylabel(\"Precipitación (mm) / Precipitation (mm)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =========================\n",
    "# Optional: error distribution (best)\n",
    "# =========================\n",
    "\n",
    "errors = preds_best[\"y_pred_mm\"].values - preds_best[\"y_true_mm\"].values\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(errors, bins=60)\n",
    "plt.title(\"Distribución del error / Error distribution\")\n",
    "plt.xlabel(\"Error (mm) / Error (mm)\")\n",
    "plt.ylabel(\"Frecuencia / Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94e18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =========================\n",
    "# Next steps (notes)\n",
    "# =========================\n",
    "\n",
    "print(\n",
    "    \"\\nNext steps / Próximos pasos:\\n\"\n",
    "    \"1) If the model underpredicts spikes, consider log target (USE_LOG_TARGET=True) or a two-stage model.\\n\"\n",
    "    \"2) Try classification (rain/no-rain) + regression for positive-rain days.\\n\"\n",
    "    \"3) Add physically motivated interactions (e.g., humidity x cloud cover) and evaluate ablation again.\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc7be4",
   "metadata": {},
   "source": [
    "Conclusions – Feature Engineering & Modeling (EN / ES)\n",
    "\n",
    "Conclusions (English)\n",
    "\n",
    "This feature engineering and modeling exercise shows that daily precipitation is best explained by a combination of physical state, seasonality, and atmospheric memory.\n",
    "\n",
    "Models relying solely on instantaneous atmospheric variables (temperature, humidity, pressure, wind) or seasonal proxies perform poorly. In contrast, features that encode temporal persistence—such as lagged precipitation and rolling accumulations—provide a substantial improvement in predictive skill, confirming the importance of atmospheric memory in precipitation processes.\n",
    "\n",
    "The best-performing experiment (EXP6_full), combining base variables, seasonal features, and memory features, achieved an R² of approximately 0.66, which is strong for daily precipitation modeling given the highly skewed and intermittent nature of rainfall. Error analysis shows that predictions are generally accurate for low to moderate precipitation but tend to underestimate extreme rainfall events, a known and expected limitation when modeling rare convective extremes with standard regression objectives.\n",
    "\n",
    "Overall, the results demonstrate that physically motivated feature engineering, combined with non-linear models such as Random Forests, can capture a significant portion of daily precipitation variability without relying on high-resolution or mesoscale predictors.\n",
    "\n",
    "⸻\n",
    "\n",
    "Conclusiones (Español)\n",
    "\n",
    "Este ejercicio de feature engineering y modelado muestra que la precipitación diaria se explica mejor mediante una combinación de estado físico atmosférico, estacionalidad y memoria atmosférica.\n",
    "\n",
    "Los modelos que utilizan únicamente variables instantáneas (temperatura, humedad, presión, viento) o proxies estacionales presentan un desempeño limitado. En cambio, las variables que incorporan persistencia temporal, como retardos de precipitación y acumulados móviles, mejoran significativamente la capacidad predictiva, confirmando el rol clave de la memoria atmosférica en los procesos de precipitación.\n",
    "\n",
    "El mejor experimento (EXP6_full), que combina variables base, estacionales y de memoria, alcanzó un R² cercano a 0.66, un valor elevado para precipitación diaria dada su distribución altamente asimétrica y episódica. El análisis de errores indica buen desempeño en precipitaciones bajas y moderadas, con una subestimación sistemática de eventos extremos, una limitación esperable al modelar fenómenos raros mediante enfoques de regresión estándar.\n",
    "\n",
    "En conjunto, los resultados demuestran que un feature engineering con criterio físico, junto con modelos no lineales como Random Forest, permite capturar una parte sustancial de la variabilidad diaria de la precipitación sin necesidad de información de mesoescala o alta resolución."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weather-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
